# utils/annotator.py

import whisper
from pyannote.audio import Pipeline
from datetime import timedelta

def diarize_and_transcribe(audio_file_path):
    print(f"ğŸ§ Loading audio from: {audio_file_path}")
    
    # ğŸ”¤ Load Whisper
    print("ğŸ”¤ Loading Whisper model...")
    model = whisper.load_model("base")

    print("ğŸ“ Transcribing with Whisper...")
    result = model.transcribe(audio_file_path, word_timestamps=True)

    print("ğŸ”Š Loading PyAnnote diarization pipeline...")
    pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization")

    print("ğŸ§  Performing speaker diarization...")
    diarization = pipeline(audio_file_path)

    print("ğŸ“ Aligning transcription with speakers...")
    annotated = []

    for turn, _, speaker in diarization.itertracks(yield_label=True):
        speaker_text = ""
        for segment in result["segments"]:
            if segment["start"] >= turn.start and segment["end"] <= turn.end:
                speaker_text += segment["text"].strip() + " "
        if speaker_text.strip():
            start = str(timedelta(seconds=int(turn.start)))
            end = str(timedelta(seconds=int(turn.end)))
            annotated.append(f"[{speaker}] ({start} - {end}) {speaker_text.strip()}")

    # ğŸ’¾ Save to text file
    transcript_path = audio_file_path.replace(".wav", "_annotated.txt")
    with open(transcript_path, "w") as f:
        for line in annotated:
            f.write(line + "\n")

    print(f"âœ… Annotated transcript saved to: {transcript_path}")
